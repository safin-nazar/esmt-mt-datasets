{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP+UgQDAoqYqpCAoRoDgkIb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8d9WGOMEfivB"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/My Drive/ThesisProject')\n","\n","%ls"],"metadata":{"id":"mq4P_uAxfonP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","!pip install pgeocode\n","import pgeocode\n","import numpy as np\n","import statsmodels.api as sm\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","from sklearn.linear_model import Ridge, Lasso\n","from itertools import combinations\n","import statsmodels.formula.api as smf\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import NearestNeighbors\n","\n","!pip install openpyxl\n","df = pd.read_excel('british-ai-startups.xlsx')\n","df"],"metadata":{"id":"dmB2RqKEfsGM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"Ua672vz7fuqg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Replace NaN values with an empty string\n","df['AIUseCase1'] = df['AIUseCase1'].fillna('')\n","df['AIUseCase2'] = df['AIUseCase2'].fillna('')\n","\n","# Concatenate AIUseCase1 and AIUseCase2 columns\n","df['FullDescription'] = df['AIUseCase1'] + ' ' + df['AIUseCase2']\n","\n","# Function to check for any form of 'personalization' or 'personalisation'\n","def check_personalization(row):\n","    keywords = ['personalization', 'personalisation']\n","    for col in ['Purpose1', 'Purpose2', 'Purpose3']:\n","        for keyword in keywords:\n","            if keyword in str(row[col]).lower():\n","                return 1\n","    return 0\n","\n","# Apply the function to each row\n","df['Personalization'] = df.apply(check_personalization, axis=1)\n","\n","# Convert 'IncorporationDate' to datetime\n","df['IncorporationDate'] = pd.to_datetime(df['IncorporationDate'])\n","\n","# Extract the year and create a new column 'FoundedYear'\n","df['FoundedYear'] = df['IncorporationDate'].dt.year\n","\n","# Function to convert 1.0 to 1 and NaN to 0\n","def convert_to_binary(column):\n","    return column.apply(lambda x: 1 if x == 1.0 else 0)\n","\n","# Apply the function to the specified columns\n","df['prolific_investor'] = convert_to_binary(df['prolific_investor'])\n","df['large_investor'] = convert_to_binary(df['large_investor'])\n","df['us_investor'] = convert_to_binary(df['us_investor'])\n","\n","# Convert boolean values to binary (True -> 1, False -> 0)\n","df['academic_founders'] = df['academic_founders'].astype(int)\n","df['expert_founders'] = df['expert_founders'].astype(int)\n","df['serial_founders'] = df['serial_founders'].astype(int)"],"metadata":{"id":"_AN0ba7nfw8p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to standardize website URLs\n","def standardize_url(url):\n","    # Remove the protocol (http, https)\n","    url = re.sub(r'^https?://', '', url)\n","    # Add 'www.' prefix if not present\n","    if not url.startswith('www.'):\n","        url = 'www.' + url\n","    return url\n","\n","# Apply the function to the Website column\n","df['Website'] = df['Website'].apply(standardize_url)\n","\n","# Dictionary to map old values to new values\n","replacement_dict = {\n","    'b2b': 'B2B',\n","    'b2c': 'B2C',\n","    'b2b b2c third': 'B2M',\n","    'b2b b2c': 'B2M',\n","    'unclear': '',\n","    'b2b third': 'B2B',\n","    'third': '',\n","    'b2c third': 'B2C'\n","}\n","\n","# Replace the values in the 'customer' column\n","df['customer'] = df['customer'].replace(replacement_dict)"],"metadata":{"id":"9BtqvCe_fxvz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Drop the 'AIUseCase1' column\n","df = df.drop(columns=['AIUseCase1'])\n","\n","# Drop the 'AIUseCase2' column\n","df = df.drop(columns=['AIUseCase2'])\n","\n","# Drop the original 'IncorporationDate' column\n","df = df.drop(columns=['IncorporationDate'])\n","\n","# Drop the 'value' column\n","df = df.drop(columns=['value'])\n","\n","# Drop the 'platform' column\n","df = df.drop(columns=['platform'])"],"metadata":{"id":"mEQfqxaAfzww"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Initialize the geolocation database for the UK\n","nomi = pgeocode.Nominatim('GB')\n","\n","# Function to get the county from a postal code\n","def get_county(postal_code):\n","    location = nomi.query_postal_code(postal_code)\n","    if location is not None and location.county_name:\n","        return location.county_name\n","    else:\n","        return \"Unknown\"\n","\n","# Apply the function to the DataFrame and create a new 'County' column\n","df['County'] = df['PostalCode'].apply(get_county)\n","\n","# Function to get the place from a postal code\n","def get_place(postal_code):\n","    location = nomi.query_postal_code(postal_code)\n","    if location is not None:\n","        return location.place_name\n","    else:\n","        return \"Unknown\"\n","\n","# Apply the function to the DataFrame and create a new 'Place' column\n","df['Place'] = df['PostalCode'].apply(get_place)"],"metadata":{"id":"iDiX-sjzf2eS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path = 'british-ai-startups-final.csv'\n","df.to_csv(file_path, index=False)\n","df.info()"],"metadata":{"id":"qkFCloZff36C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setting up the visualizations\n","sns.set(style=\"whitegrid\")\n","plt.figure(figsize=(18, 16))\n","\n","# Distribution of Personalization\n","plt.subplot(3, 3, 1)\n","personalization_counts = df['Personalization'].value_counts()\n","sns.countplot(data=df, x='Personalization')\n","for i, count in enumerate(personalization_counts):\n","    plt.text(i, count, f'{count}\\n({count/sum(personalization_counts)*100:.1f}%)', ha='center', va='bottom')\n","plt.title('Distribution of Personalization', pad=20)\n","plt.xlabel('Personalization')\n","plt.ylabel('Count')\n","\n","# Top 10 sectors by the number of startups\n","plt.subplot(3, 3, 2)\n","sector_counts = df['Sector1'].value_counts().head(10)\n","sns.barplot(y=sector_counts.index, x=sector_counts.values, palette=\"viridis\")\n","for i, (count, label) in enumerate(zip(sector_counts.values, sector_counts.index)):\n","    plt.text(count, i, f'{count}\\n({count/sum(sector_counts)*100:.1f}%)', va='center')\n","plt.title('Top 10 Sectors by Number of Startups', pad=20)\n","plt.xlabel('Number of Startups')\n","plt.ylabel('Sector')\n","\n","# Distribution of FoundedYear (without percentage annotations)\n","plt.subplot(3, 3, 3)\n","sns.histplot(data=df, x='FoundedYear', bins=15, kde=True, color='blue')\n","plt.title('Distribution of Founded Year', pad=20)\n","plt.xlabel('Founded Year')\n","plt.ylabel('Frequency')\n","\n","# Customer Type Distribution (Pie Chart with percentages)\n","plt.subplot(3, 3, 4)\n","customer_counts = df['customer'].value_counts()\n","plt.pie(customer_counts, labels=customer_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette(\"coolwarm\", len(customer_counts)))\n","plt.title('Customer Type Distribution', pad=20)\n","\n","# Count of Startups by County\n","plt.subplot(3, 3, 5)\n","county_counts = df['County'].value_counts().head(10)\n","sns.barplot(y=county_counts.index, x=county_counts.values, palette=\"magma\")\n","for i, (count, label) in enumerate(zip(county_counts.values, county_counts.index)):\n","    plt.text(count, i, f'{count}\\n({count/sum(county_counts)*100:.1f}%)', va='center')\n","plt.title('Top 10 Counties by Number of Startups', pad=20)\n","plt.xlabel('Number of Startups')\n","plt.ylabel('County')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"ehHJL009f7sq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plotting top 10 and bottom 10 sectors by median Funding and Valuation\n","\n","plt.figure(figsize=(16, 16))\n","\n","sector_funding_valuation = df.groupby('Sector1').agg({\n","    'FundingCumulative2023Q2': 'median',\n","    'LatestPreMoneyValuationGBP': 'median'\n","}).reset_index()\n","\n","top10_funding = sector_funding_valuation.sort_values(by='FundingCumulative2023Q2', ascending=False).head(10)\n","bottom10_funding = sector_funding_valuation.sort_values(by='FundingCumulative2023Q2').head(10)\n","top10_valuation = sector_funding_valuation.sort_values(by='LatestPreMoneyValuationGBP', ascending=False).head(10)\n","bottom10_valuation = sector_funding_valuation.sort_values(by='LatestPreMoneyValuationGBP').head(10)\n","\n","\n","# Top 10 sectors by median funding\n","plt.subplot(4, 1, 1)\n","plt.barh(top10_funding['Sector1'], top10_funding['FundingCumulative2023Q2'], color='green')\n","plt.xlabel('Median Funding (GBP)')\n","plt.ylabel('Sectors')\n","plt.title('Top 10 Sectors by Median Funding')\n","\n","# Bottom 10 sectors by median funding\n","plt.subplot(4, 1, 2)\n","plt.barh(bottom10_funding['Sector1'], bottom10_funding['FundingCumulative2023Q2'], color='red')\n","plt.xlabel('Median Funding (GBP)')\n","plt.ylabel('Sectors')\n","plt.title('Bottom 10 Sectors by Median Funding')\n","\n","# Top 10 sectors by median valuation\n","plt.subplot(4, 1, 3)\n","plt.barh(top10_valuation['Sector1'], top10_valuation['LatestPreMoneyValuationGBP'], color='blue')\n","plt.xlabel('Median Valuation (GBP)')\n","plt.ylabel('Sectors')\n","plt.title('Top 10 Sectors by Median Valuation')\n","\n","# Bottom 10 sectors by median valuation\n","plt.subplot(4, 1, 4)\n","plt.barh(bottom10_valuation['Sector1'], bottom10_valuation['LatestPreMoneyValuationGBP'], color='orange')\n","plt.xlabel('Median Valuation (GBP)')\n","plt.ylabel('Sectors')\n","plt.title('Bottom 10 Sectors by Median Valuation')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"BiBEujkSf_yv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Identifying binary variables\n","binary_columns = [col for col in df.columns if df[col].dropna().isin([0, 1]).all()]\n","\n","# Analyzing binary variables w.r.t. Personalization\n","plt.figure(figsize=(18, 12))\n","sns.set(style=\"whitegrid\")\n","\n","# Create plots for each binary variable showing percentage of startups with and without Personalization\n","for i, col in enumerate(binary_columns[:-1]):  # Exclude 'Personalization' itself\n","    plt.subplot(3, 2, i + 1)\n","    counts = df.groupby([col, 'Personalization']).size().unstack(fill_value=0)\n","    counts_percentage = counts.div(counts.sum(axis=1), axis=0) * 100\n","\n","    # Plotting the data\n","    counts_percentage.plot(kind='bar', stacked=True, color=['#ff9999','#66b3ff'], ax=plt.gca())\n","    plt.title(f'{col.replace(\"_\", \" \").capitalize()}')\n","    plt.xlabel(col.replace(\"_\", \" \").capitalize())\n","    plt.ylabel('Percentage')\n","    plt.xticks(rotation=0)\n","    for p in plt.gca().patches:\n","        plt.gca().annotate(f'{p.get_height():.1f}%', (p.get_x() * 1.005, p.get_y() + p.get_height() / 2), ha='center', va='center')\n","    plt.legend(title='Personalization', labels=['No', 'Yes'])\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"5WVKBoEcgC6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the correlation matrix\n","correlation_data = df[['LatestPreMoneyValuationGBP', 'FundingCumulative2023Q2',\n","                         'Personalization', 'expert_founders', 'serial_founders',\n","                         'large_investor', 'us_investor', 'FoundedYear']]\n","\n","correlations = correlation_data.corr()\n","\n","# Setting up the figure for a better visualization of the correlation matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(correlations, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n","plt.title('Correlation Matrix of Success Metrics and Factors')\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"vXon0A4jgDz3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming 'df' contains the dataset\n","# Grouping data by 'Personalization' and calculating mean valuation and funding for each group\n","personalization_effect = df.groupby('Personalization').agg({\n","    'LatestPreMoneyValuationGBP': 'mean',\n","    'FundingCumulative2023Q2': 'mean'\n","}).reset_index()\n","\n","# Plotting the results\n","plt.figure(figsize=(12, 6))\n","\n","# Valuation plot\n","plt.subplot(1, 2, 1)\n","plt.bar(personalization_effect['Personalization'], personalization_effect['LatestPreMoneyValuationGBP'], color=['blue', 'orange'])\n","plt.xticks([0, 1], ['No Personalization', 'Personalization'])\n","plt.xlabel('Personalization')\n","plt.ylabel('Average Valuation (GBP)')\n","plt.title('Average Valuation by Personalization')\n","\n","# Funding plot\n","plt.subplot(1, 2, 2)\n","plt.bar(personalization_effect['Personalization'], personalization_effect['FundingCumulative2023Q2'], color=['blue', 'orange'])\n","plt.xticks([0, 1], ['No Personalization', 'Personalization'])\n","plt.xlabel('Personalization')\n","plt.ylabel('Average Funding (GBP)')\n","plt.title('Average Funding by Personalization')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"elCNuC2YgFmW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = df.copy()\n","\n","# Define the independent variables\n","X = data[['Personalization', 'expert_founders', 'serial_founders', 'prolific_investor', 'large_investor', 'us_investor', 'FoundedYear']]\n","\n","# Add a constant to the model (intercept)\n","X = sm.add_constant(X)\n","\n","# Calculate VIF for each feature\n","vif_data = pd.DataFrame()\n","vif_data[\"Feature\"] = X.columns\n","vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n","\n","print(vif_data)"],"metadata":{"id":"GV3TzcSlgJbR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the dependent variables\n","dependent_vars = {\n","    'Funding': 'FundingCumulative2023Q2',\n","    'Valuation': 'LatestPreMoneyValuationGBP'\n","}\n","\n","# Define the endogenous variable (independent variable of interest)\n","endog_var = 'Personalization'\n","\n","# Define the set of potential instrumental variables\n","potential_instruments = ['academic_founders', 'expert_founders', 'serial_founders',\n","                         'prolific_investor', 'large_investor', 'us_investor',\n","                         'FoundedYear']\n","\n","# Define other covariates (controls)\n","controls = ['expert_founders', 'serial_founders', 'prolific_investor', 'large_investor', 'us_investor']\n","\n","# Store results\n","results = []\n","\n","# Iterate over each dependent variable (Funding and Valuation)\n","for dep_label, dep_var in dependent_vars.items():\n","    best_model = None\n","    best_aic = float('inf')\n","\n","    # Iterate over all potential instruments to find the best one\n","    for instrument in potential_instruments:\n","        if instrument == endog_var or instrument in controls:\n","            continue\n","\n","        # First stage: Regress Personalization on the instrument and controls\n","        first_stage = sm.OLS(data[endog_var], sm.add_constant(data[[instrument] + controls])).fit()\n","        data['Personalization_hat'] = first_stage.predict()\n","\n","        # Second stage: Regress the dependent variable on the predicted values from the first stage and controls\n","        second_stage = sm.OLS(data[dep_var], sm.add_constant(data[['Personalization_hat'] + controls])).fit()\n","\n","        # Record the model with the lowest AIC\n","        if second_stage.aic < best_aic:\n","            best_aic = second_stage.aic\n","            best_model = (dep_label, instrument, second_stage)\n","\n","    results.append(best_model)\n","\n","# Print the best model summary for each dependent variable\n","for dep_label, instrument, model in results:\n","    print(f\"Best Instrument for {dep_label}: {instrument}\")\n","    print(model.summary())\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")"],"metadata":{"id":"xmeDpf5cgN3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the treatment and outcome variables\n","treatment = data['Personalization']\n","outcome_valuation = data['LatestPreMoneyValuationGBP']\n","outcome_funding = data['FundingCumulative2023Q2']\n","\n","# Define the covariates\n","covariates = data[['expert_founders', 'serial_founders', 'prolific_investor', 'large_investor', 'us_investor']]\n","\n","# Standardize the covariates\n","scaler = StandardScaler()\n","covariates_scaled = scaler.fit_transform(covariates)\n","\n","# Fit the logistic regression model to estimate propensity scores\n","logistic = LogisticRegression()\n","logistic.fit(covariates_scaled, treatment)\n","propensity_scores = logistic.predict_proba(covariates_scaled)[:, 1]\n","\n","# Match the treated and control units using nearest neighbors on the propensity score\n","treated_indices = np.where(treatment == 1)[0]\n","control_indices = np.where(treatment == 0)[0]\n","\n","nn = NearestNeighbors(n_neighbors=1, algorithm='ball_tree')\n","nn.fit(propensity_scores[control_indices].reshape(-1, 1))\n","distances, indices = nn.kneighbors(propensity_scores[treated_indices].reshape(-1, 1))\n","\n","# Find matched control indices\n","matched_control_indices = control_indices[indices.flatten()]\n","\n","# Calculate the Average Treatment Effect on the Treated (ATT) for valuation and funding\n","att_valuation = outcome_valuation[treated_indices].mean() - outcome_valuation[matched_control_indices].mean()\n","att_funding = outcome_funding[treated_indices].mean() - outcome_funding[matched_control_indices].mean()\n","\n","print(f\"ATT for Valuation: {att_valuation}\")\n","print(f\"ATT for Funding: {att_funding}\")"],"metadata":{"id":"CwxmhN3ugQbZ"},"execution_count":null,"outputs":[]}]}